{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import canvas_interface\n",
    "import lesson_content\n",
    "from datetime import date\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from credentials import Credentials\n",
    "from saturncloud import UpdatedLinksDf, update_course, make_saturn_button, GetSaturnLink\n",
    "from markdown import markdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = Credentials('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = UpdatedLinksDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_course(auth.API_KEY, auth.API_PATH, auth.instance, 7, links.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "course = canvas_interface.Course(auth.API_KEY, auth.API_PATH, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        'Authorization': f'Bearer {auth.API_KEY}'\n",
    "    }\n",
    "\n",
    "done = False\n",
    "page = 1\n",
    "assignments = []\n",
    "assn_url = f\"{auth.API_PATH}/courses/{2}/assignments?per_page=100&page={page}\"\n",
    "assn_response = requests.get(assn_url, headers=headers)\n",
    "response_list = assn_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assn_response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        'Authorization': f'Bearer {auth.API_KEY}'\n",
    "    }\n",
    "\n",
    "done = False\n",
    "page = 1\n",
    "assignments = []\n",
    "while(not done):\n",
    "    assn_url = f\"{auth.API_PATH}/courses/{3}/assignments?per_page=100&page={page}\"\n",
    "    assn_response = requests.get(assn_url, headers=headers)\n",
    "    response_list = assn_response.json()\n",
    "    assignments.extend(response_list)\n",
    "    \n",
    "    if (len(response_list) < 100):\n",
    "        done = True\n",
    "    else:\n",
    "        page += 1\n",
    "        \n",
    "clean_list = list(filter(lambda x: x['description'] != None, assignments))\n",
    "\n",
    "saturncloud_tag = 'saturnenterprise.io/dash/resources'\n",
    "saturncloud_assign = list(filter(lambda x: saturncloud_tag in x['description'], clean_list))\n",
    "\n",
    "\n",
    "assignments = saturncloud_assign\n",
    "number_of_assignments = len(saturncloud_assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturncloud_tag = 'saturnenterprise.io/dash/resources'\n",
    "saturncloud_assign = []\n",
    "for x in assignments:\n",
    "    print(x['id'])\n",
    "    if 'external_tool_tag_attributes' not in x.keys():\n",
    "        if saturncloud_tag in x['description']:\n",
    "            saturncloud_assign.append(x)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        print('error', x['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturncloud_tag = 'saturnenterprise.io/dash/resources'\n",
    "saturncloud_assign = list(filter(lambda x: saturncloud_tag in x['description'] if 'external_tool_tag_attributes' in x.keys() else None, assignments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(assignments):\n",
    "    if v['id'] == 283:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 100,\n",
       " 'description': '<div data-org=\"learn-co-curriculum\" data-repo=\"dsc-filtering-lab-v2-4\" id=\"git-data-element\"></div>\\n<header class=\"fis-header\" style=\"visibility: hidden;\"><a class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-filtering-lab-v2-4\" target=\"_blank\"><img alt=\"GitHub Repo\" id=\"repo-img\" title=\"Open GitHub Repo\"></a><a class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-filtering-lab-v2-4/issues/new\" target=\"_blank\"><img alt=\"Create New Issue\" id=\"issue-img\" title=\"Create New Issue\"></a></header>\\n<h2>Introduction</h2>\\n<p>NASA wants to go to Mars! Before they build their rocket, NASA needs to track information about all of the planets in the Solar System. In this lab, you\\'ll practice querying the database with various <code>SELECT</code> statements. This will include selecting different columns and implementing other SQL clauses like <code>WHERE</code> to return the data desired.</p>\\n<p><img src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-filtering-lab-v2-4/master/images/planets.png\" alt=\"image of solar system\" width=\"600\"></p>\\n<h2>Objectives</h2>\\n<p>You will practice the following:</p>\\n<ul>\\n<li>Retrieve a subset of records from a table using a <code>WHERE</code> clause</li>\\n<li>Filter results using conditional operators such as <code>BETWEEN</code>, <code>IS NULL</code>, and <code>LIKE</code></li>\\n<li>Apply an aggregate function to the result of a filtered query</li>\\n\\n<p id=\"saturncloud_button_07_20_2023\"><span style=\"color: #34495e;\"><span style=\"font-size: 24pt; background-color: #3598db; border: 2px solid;\"><a class=\"inline_disabled\" style=\"background-color: #3598db; color: #34495e;\" href=\"https://app.codeclan.saturnenterprise.io/dash/resources?workspacePath=notebooks%2Fworkspace%2Fflatiron-curriculum%2FPhase1%2Fdsc-analyzing-macbeth-project-pandas-v2-1%2Findex.ipynb&amp;apply=true&amp;recipe=%7B%0A++%22name%22%3A+%22ds-course-phase1%22%2C%0A++%22image%22%3A+%7B%0A++++%22name%22%3A+%22flatiron-school%22%2C%0A++++%22version%22%3A+%222023.06.20%22%2C%0A++++%22owner%22%3A+%22production%22%0A++%7D%2C%0A++%22description%22%3A+%22%22%2C%0A++%22environment_variables%22%3A+%7B%22TF_CPP_MIN_LOG_LEVEL%22%3A+%223%22%7D%2C%0A++%22working_directory%22%3A+%22%2Fhome%2Fjovyan%2Fworkspace%22%2C%0A++%22start_script%22%3A+%22mkdir+-p+%2Fhome%2Fjovyan%2Fflatiron-curriculum-clone%5Cnmkdir+-p+%2Fhome%2Fjovyan%2Fworkspace%2Fflatiron-curriculum%5Cnaws+s3+sync+s3%3A%2F%2Fflatiron-curriculum%2FPhase1+%2Fhome%2Fjovyan%2Fflatiron-curriculum-clone%2FPhase1+--no-sign-request%5Cncp+-rn+%2Fhome%2Fjovyan%2Fflatiron-curriculum-clone%2F%2A+%2Fhome%2Fjovyan%2Fworkspace%2Fflatiron-curriculum%2F%5Cn%22%2C%0A++%22git_repositories%22%3A+%5B%5D%2C%0A++%22secrets%22%3A+%5B%5D%2C%0A++%22jupyter_server%22%3A+%7B%0A++++%22instance_type%22%3A+%22large%22%2C%0A++++%22disk_space%22%3A+%2210Gi%22%2C%0A++++%22auto_shutoff%22%3A+%221+hour%22%2C%0A++++%22start_ssh%22%3A+false%2C%0A++++%22use_spot_instance%22%3A+false%2C%0A++++%22start_dind%22%3A+false%2C%0A++++%22self_destruct%22%3A+false%2C%0A++++%22status%22%3A+%22running%22%2C%0A++++%22expose_app_port%22%3A+true%0A++%7D%2C%0A++%22visibility%22%3A+%22owner%22%2C%0A++%22schema_version%22%3A+%222022.08.01%22%0A%7D%0A\" target=\"_blank\"><span style=\"background-color: #ced4d9;\">&nbsp;Click Here to Launch Lesson&nbsp;</span></a></span></span></p></ul>',\n",
       " 'due_at': None,\n",
       " 'unlock_at': None,\n",
       " 'lock_at': None,\n",
       " 'points_possible': 0.0,\n",
       " 'grading_type': 'points',\n",
       " 'assignment_group_id': 15,\n",
       " 'grading_standard_id': None,\n",
       " 'created_at': '2023-07-17T17:42:49Z',\n",
       " 'updated_at': '2023-07-20T18:46:11Z',\n",
       " 'peer_reviews': False,\n",
       " 'automatic_peer_reviews': False,\n",
       " 'position': 1,\n",
       " 'grade_group_students_individually': False,\n",
       " 'anonymous_peer_reviews': False,\n",
       " 'group_category_id': None,\n",
       " 'post_to_sis': False,\n",
       " 'moderated_grading': False,\n",
       " 'omit_from_final_grade': False,\n",
       " 'intra_group_peer_reviews': False,\n",
       " 'anonymous_instructor_annotations': False,\n",
       " 'anonymous_grading': False,\n",
       " 'graders_anonymous_to_graders': False,\n",
       " 'grader_count': 0,\n",
       " 'grader_comments_visible_to_graders': True,\n",
       " 'final_grader_id': None,\n",
       " 'grader_names_visible_to_final_grader': True,\n",
       " 'allowed_attempts': -1,\n",
       " 'annotatable_attachment_id': None,\n",
       " 'hide_in_gradebook': False,\n",
       " 'secure_params': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJsdGlfYXNzaWdubWVudF9pZCI6Ijk2MmU2MDkyLTVhNmYtNDBhMC05MjdmLTI0ZTU0YjliMzU0MyIsImx0aV9hc3NpZ25tZW50X2Rlc2NyaXB0aW9uIjoiXHUwMDNjZGl2IGRhdGEtb3JnPVwibGVhcm4tY28tY3VycmljdWx1bVwiIGRhdGEtcmVwbz1cImRzYy1maWx0ZXJpbmctbGFiLXYyLTRcIiBpZD1cImdpdC1kYXRhLWVsZW1lbnRcIlx1MDAzZVx1MDAzYy9kaXZcdTAwM2Vcblx1MDAzY2hlYWRlciBjbGFzcz1cImZpcy1oZWFkZXJcIiBzdHlsZT1cInZpc2liaWxpdHk6IGhpZGRlbjtcIlx1MDAzZVx1MDAzY2EgY2xhc3M9XCJmaXMtZ2l0LWxpbmtcIiBocmVmPVwiaHR0cHM6Ly9naXRodWIuY29tL2xlYXJuLWNvLWN1cnJpY3VsdW0vZHNjLWZpbHRlcmluZy1sYWItdjItNFwiIHRhcmdldD1cIl9ibGFua1wiXHUwMDNlXHUwMDNjaW1nIGFsdD1cIkdpdEh1YiBSZXBvXCIgaWQ9XCJyZXBvLWltZ1wiIHRpdGxlPVwiT3BlbiBHaXRIdWIgUmVwb1wiXHUwMDNlXHUwMDNjL2FcdTAwM2VcdTAwM2NhIGNsYXNzPVwiZmlzLWdpdC1saW5rXCIgaHJlZj1cImh0dHBzOi8vZ2l0aHViLmNvbS9sZWFybi1jby1jdXJyaWN1bHVtL2RzYy1maWx0ZXJpbmctbGFiLXYyLTQvaXNzdWVzL25ld1wiIHRhcmdldD1cIl9ibGFua1wiXHUwMDNlXHUwMDNjaW1nIGFsdD1cIkNyZWF0ZSBOZXcgSXNzdWVcIiBpZD1cImlzc3VlLWltZ1wiIHRpdGxlPVwiQ3JlYXRlIE5ldyBJc3N1ZVwiXHUwMDNlXHUwMDNjL2FcdTAwM2VcdTAwM2MvaGVhZGVyXHUwMDNlXG5cdTAwM2NoMlx1MDAzZUludHJvZHVjdGlvblx1MDAzYy9oMlx1MDAzZVxuXHUwMDNjcFx1MDAzZU5BU0Egd2FudHMgdG8gZ28gdG8gTWFycyEgQmVmb3JlIHRoZXkgYnVpbGQgdGhlaXIgcm9ja2V0LCBOQVNBIG5lZWRzIHRvIHRyYWNrIGluZm9ybWF0aW9uIGFib3V0IGFsbCBvZiB0aGUgcGxhbmV0cyBpbiB0aGUgU29sYXIgU3lzdGVtLiBJbiB0aGlzIGxhYiwgeW91J2xsIHByYWN0aWNlIHF1ZXJ5aW5nIHRoZSBkYXRhYmFzZSB3aXRoIHZhcmlvdXMgXHUwMDNjY29kZVx1MDAzZVNFTEVDVFx1MDAzYy9jb2RlXHUwMDNlIHN0YXRlbWVudHMuIFRoaXMgd2lsbCBpbmNsdWRlIHNlbGVjdGluZyBkaWZmZXJlbnQgY29sdW1ucyBhbmQgaW1wbGVtZW50aW5nIG90aGVyIFNRTCBjbGF1c2VzIGxpa2UgXHUwMDNjY29kZVx1MDAzZVdIRVJFXHUwMDNjL2NvZGVcdTAwM2UgdG8gcmV0dXJuIHRoZSBkYXRhIGRlc2lyZWQuXHUwMDNjL3BcdTAwM2Vcblx1MDAzY3BcdTAwM2VcdTAwM2NpbWcgc3JjPVwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL2xlYXJuLWNvLWN1ci4uLiAodHJ1bmNhdGVkKSJ9.xntXOxdoqQybymYELrHkWZGaQ2qBQuic40tEagHsy90',\n",
       " 'lti_context_id': '962e6092-5a6f-40a0-927f-24e54b9b3543',\n",
       " 'course_id': 2,\n",
       " 'name': 'Analyzing Macbeth Project Pandas V2 1',\n",
       " 'submission_types': ['none'],\n",
       " 'has_submitted_submissions': False,\n",
       " 'due_date_required': False,\n",
       " 'max_name_length': 255,\n",
       " 'in_closed_grading_period': False,\n",
       " 'graded_submissions_exist': False,\n",
       " 'is_quiz_assignment': False,\n",
       " 'can_duplicate': True,\n",
       " 'original_course_id': None,\n",
       " 'original_assignment_id': None,\n",
       " 'original_lti_resource_link_id': None,\n",
       " 'original_assignment_name': None,\n",
       " 'original_quiz_id': None,\n",
       " 'workflow_state': 'published',\n",
       " 'important_dates': False,\n",
       " 'muted': True,\n",
       " 'html_url': 'https://codeclan.instructure.com/courses/2/assignments/100',\n",
       " 'has_overrides': False,\n",
       " 'needs_grading_count': 0,\n",
       " 'sis_assignment_id': None,\n",
       " 'integration_id': None,\n",
       " 'integration_data': {},\n",
       " 'published': True,\n",
       " 'unpublishable': True,\n",
       " 'only_visible_to_overrides': False,\n",
       " 'locked_for_user': False,\n",
       " 'submissions_download_url': 'https://codeclan.instructure.com/courses/2/assignments/100/submissions?zip=1',\n",
       " 'is_master_course_master_content': True,\n",
       " 'restricted_by_master_course': False,\n",
       " 'post_manually': False,\n",
       " 'anonymize_students': False,\n",
       " 'require_lockdown_browser': False,\n",
       " 'restrict_quantitative_data': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = '/Users/jeffreyhinkle/cooldown/dsc-statistical-power-lab/README.md'\n",
    "with open(path, 'r') as f:\n",
    "    raw_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pygments in /Users/jeffreyhinkle/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (2.7.1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Poisson Distribution\\n\\n## Introduction\\n\\nIn this lesson, you\\'ll learn about the **Poisson Distribution** and explore some practical ways you can use it. \\n\\n## Objectives\\n\\nYou will be able to:\\n\\n* Explain the parameters of the Poisson distribution and its use cases\\n\\n## What is the Poisson Distribution?\\n\\nThe **Poisson Distribution** is yet another statistical distribution you can use to answer questions about the probability of a given number of successes, the probability of success, and a series of independent trials. Specifically, the Poisson Distribution allows you to calculate the probability of a given event happening by examining the mean number of events that happen in a given time period. Given a set time period, we can use the Poisson Distribution to predict how many times a given event will happen over that time period. To help you better understand this, let\\'s examine a few sample questions that we can answer using the Poisson Distribution. \\n\\n### Sample Question 1\\n\\nAn average of 20 customers walk into a store in a given hour.  What is the probability that 25 customers walk into a store in the next hour?\\n\\n### Sample Question 2\\n\\nA police officer pulls over an average of 3 people for speeding violations per shift.  What is the probability that the officer will pull over two people for speeding violations during their next shift?\\n\\n## Understanding the Parameters\\n\\nIn order to use the Poisson Distribution, we only need to know a few parameters:\\n\\n$\\\\mu$: The average number of successes over a given time period. For instance, the average number of customers that walk into a store in a given hour, or the average number of speeding violations a police officer sees in a shift.\\n\\n$x$: Our random variable - the number of successes we want to find the probability mass of given our knowledge of $\\\\mu$.\\n\\n\\n### Relationship to the Binomial Distribution\\n\\nThe Poisson distribution has a special relation to the binomial distribution. The theoretical underpinnings are as follows. Imagine that we take a time period and break it into $n$ subintervals that are so small that at most one successful event could occur. We can then imagine that for any of these subintervals, a binomial distribution could apply where there is some probability of the event occurring, $p$, a probability $q=1-p$ that the event does not occur, and a probability of 0 that more than one event occurs. We assume that as we cut time into smaller and smaller intervals, the chance of success should go down. If we take the limit of the binomial distribution as $n$ goes to infinity (more and more subintervals that are progressively smaller and smaller), the result is the Poisson distribution.\\n\\nBinomial Probability Distribution:\\n$$p(x) = \\\\binom{n}{x}p^x(1-p)^{n-x}$$\\n\\n$$\\\\lambda = n*p$$\\n\\nPoisson Probability Distribution: $$p(x) = \\\\frac{\\\\lambda^xe^{-\\\\lambda}}{x!}$$\\n\\nAlso note that lambda $\\\\lambda$ is the now the average number of successes that we anticipate in a given interval: the probability $p$ of success, times the number of intervals $n$. This is then exactly how the Poisson is used in practice--if we know the average number of occurrences in a given interval, what is the probability that the actual number of occurrences is slightly more, slightly less, far more or far less?\\n\\n### Understanding the Formula\\n\\nLet\\'s take another look at the formula for the Poisson Probability Distribution:\\n\\n$$p(x) = \\\\frac{\\\\lambda^xe^{-\\\\lambda}}{x!}$$\\n\\nIn the other statistical distributions we\\'ve explored, we were explicitly given the probability of success or failure as one of our parameters. In this example, we are not given this probability--however, we know how likely an event is to occur the mean number of times over a given time period, which means that we actually **do** know the probability--we just need to do some basic calculations to uncover this probability. \\n\\nFor instance, if we know that 6 customers walk into a store per hour, we also know enough to calculate the probability that a customer walks in during a given minute. We do this by just dividing the mean number of customers by the length of our interval! \\n\\n$$p = \\\\frac{6}{60} = 0.1$$\\n\\nThere is no expectation that customers will walk into a store in evenly spaced intervals--a customer may walk in every 10 minutes on the dot--however, we may also see 3 customers walk in during the first 5 minutes, 3 more customers 10 minutes later, and no other customers for the rest of the hour.  Remember, these events are independent, and this is also the mean number per hour.  This doesn\\'t mean that we have 6 customers every hour - it\\'s possible that we do, but it\\'s also possible that we have 12 customers one hour and no customers the next hour. It\\'s also possible that in a 10-hour day, 60 customers enter the store during the first hour, and then none for the rest of the day. If your intuition is telling you that this is possible, but not **_plausible_** because it has a very low probability of happening, you\\'re right--and the probability of this happening is exactly what the Poisson Distribution allows us to calculate!\\n\\nIn light of this, it makes sense for us to calculate the probability that a customer will walk in during **_any given minute_**, which we discovered by just dividing our mean number of customers per hour by the number of minutes in our interval, showing us that the probability of a customer walking in during any given minute is 0.1, or 10%. This number is our $\\\\lambda$ parameter.\\n\\nTake a look at the following graph - note the relationship of each line to its given $\\\\lambda$ parameter:\\n\\n<img src=\\'images/new_poisson.png\\' width=\"400\">\\n\\n### The Rest of the Formula\\n\\nDon\\'t let the other terms in that equation scare you - you\\'ve seen them before, and even if you haven\\'t they\\'re quite easy to work with:\\n\\n$e$: Euler\\'s Constant, which is $e \\\\approx 2.71828$. You may also know this as the base of the natural logarithm. On calculators, this is the `exp` button.  In Python, we can access it by using NumPy\\'s `np.exp()` function. \\n\\n$x!$: The factorial of $x$.  For example, $3! = 3 * 2 * 1 = 6$ \\n\\n## Summary\\n\\nIn this lesson, you learned about the Poisson Distribution, the Poisson Probability Formula, and how you can use this distribution to solve real-world problems!\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import latex\n",
    "m_down = latex.latex_to_img(raw_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdown import markdown\n",
    "html = markdown(raw_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "html1 = html.replace('\\n', '')\n",
    "html2 = html1.replace(r\"\\\\'\" ,\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<h1>Statistical Power - Lab</h1><h2>Introduction</h2><p>In this lesson, you\\'ll practice doing a power-analysis during experimental design. As you\\'ve seen, power analysis allows you to determine the sample size required to detect an effect of a given size with a given degree of confidence. In other words, it allows you to determine the probability of detecting an effect of a given size with a given level of confidence, under-sample size constraints.</p><h2>Objectives</h2><p>In this lab you will: </p><ul><li>Describe the impact of sample size and effect size on power </li><li>Perform power calculation using SciPy and Python </li><li>Demonstrate the combined effect of sample size and effect size on statistical power using simulations</li></ul><h2>Let\\'s get started!</h2><p>The following four factors have an intimate relationship:</p><ul><li>Sample size</li><li>Effect size</li><li>Significance level = $\\\\alpha$ = P(Type I error) = probability of finding an effect that is not there</li><li><strong>Power = 1 - $\\\\beta$ = 1 - P(Type II error)</strong> = probability of finding an effect that is there<ul><li>where $\\\\beta$ is the probability of a Type II error, i.e. the probability of failing to reject a false null hypothesis</li></ul></li></ul><p>Given any three of these, we can easily determine the fourth.</p><p>To start, let\\'s import the necessary libraries required for this simulation: </p><p><code>pythonimport numpy as npimport scipy.stats as statsimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as snssns.set_style(\\'darkgrid\\')</code></p><p>```python</p><h1><strong>SOLUTION</strong></h1><p>import numpy as npimport scipy.stats as statsimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as snssns.set_style(\\'darkgrid\\')```</p><h2>Scenario</h2><p>A researcher wants to study how daily protein supplementation in the elderly population will affect baseline liver fat. The study budget will allow enrollment of 24 patients. Half will be randomized to a placebo group and half to the protein supplement treatment group and the trial will be carried out over one month. It is desired to see whether the mean change in percentage of liver fat from baseline to the end of the study differs between the two groups in the study. </p><p>With this, the researcher writes the null hypothesis: </p><pre><code>There is no difference between experimental and control group mean change in percentage of liver fat</code></pre><p>$$\\\\mu_{1} = \\\\mu_{2}$$</p><p>And the alternative Hypothesis:</p><pre><code>There is a difference between experimental and control group mean change in percentage of liver fat</code></pre><p>$$\\\\mu_{1} \\\\neq \\\\mu_{2}$$</p><p>The researcher needs to know what power  will be obtained under the sample size restrictions to identify a change in mean percent liver fat of 0.17. Based on past results, a common standard deviation of 0.21 will be used for each treatment group in the power analysis. </p><p>To determine the practicality of this experimental design, you\\'ll run a power analysis simulation: </p><p>```python</p><h1>Number of patients in each group</h1><p>sample_size = None</p><h1>Control group</h1><p>control_mean = Nonecontrol_sd = None</p><h1>Experimental group</h1><p>experimental_mean = Noneexperimental_sd = None</p><h1>Set the number of simulations for our test = 1000</h1><p>n_sim = None```</p><p>```python</p><h1><strong>SOLUTION</strong></h1><h1>Number of patients in each group</h1><p>sample_size = 12</p><h1>Control group</h1><p>control_mean = 0control_sd = 0.21</p><h1>Experimental group</h1><p>experimental_mean = 0.17experimental_sd = 0.21</p><h1>Set the number of simulations for our test = 1000</h1><p>n_sim = 1000```</p><p>You can now start running simulations to run an independent t-test with above data and store the calculated p-value in our <code>p</code> array. Perform following tasks: </p><ul><li>Initialize a numpy array and fill it with <code>NaN</code> values for storing the results (p_value) of the independent t-test  </li><li><p>For a defined number of simulations (i.e., 1000), do the following:</p><ul><li>Generate a random normal variable with control mean and sd</li><li>Generate a random normal variable with experimental mean and sd</li><li>Run and independent t-test using control and experimental data</li><li>Store the p value for each test</li></ul></li><li><p>Calculate the total number and overall proportion of simulations where the null hypothesis is rejected</p></li></ul><p>```python</p><h1>For reproducibility</h1><p>np.random.seed(10)</p><h1>Initialize array to store results</h1><p>p = (np.empty(n_sim))p.fill(np.nan)</p><h1>Run a for loop for range of values in n_sim</h1><h1>number of null hypothesis rejections</h1><p>num_null_rejects = Nonepower = None</p><p>power</p><h1>0.495</h1><p>```</p><p>```python</p><h1><strong>SOLUTION</strong></h1><h1>For reproducibility</h1><p>np.random.seed(10)</p><h1>Initialize array to store results</h1><p>p = (np.empty(n_sim))p.fill(np.nan)</p><h1>Run a for loop for range of values in n_sim</h1><p>for s in range(n_sim):</p><pre><code>control = np.random.normal(loc= control_mean, scale=control_sd, size=sample_size)experimental = np.random.normal(loc= experimental_mean, scale=experimental_sd, size=sample_size)t_test = stats.ttest_ind(control, experimental)p[s] = t_test[1]</code></pre><h1>number of null hypothesis rejections</h1><p>num_null_rejects = np.sum(p &lt; 0.05)power = num_null_rejects/float(n_sim)</p><p>power```</p><pre><code>0.495</code></pre><p>These results indicate that using 12 participants in each group and with given statistics, the statistical power of the experiment is 49%. This can be interpreted as follows:</p><blockquote><p><strong>If a large effect (0.17 or greater) is truly present between control and experimental groups, then the null hypothesis (i.e. no difference with alpha 0.05) would be rejected 49% of the time. </strong></p></blockquote><h2>Sample size requirements for a given effect size</h2><p>Often in behavioral research 0.8 is accepted as a sufficient level of power.  </p><p>Clearly, this is not the case for the experiment as currently designed. Determine the required sample size in order to identify a difference of 0.17 or greater between the group means with an 80% power.</p><p>```python</p><h1>Required power</h1><p>target = 0.8```</p><p>```python</p><h1><strong>SOLUTION</strong></h1><h1>Required power</h1><p>target = 0.8```</p><p><code>pythonfrom statsmodels.stats.power import TTestIndPowerpower = TTestIndPower()</code></p><p>```python</p><h1><strong>SOLUTION</strong></h1><p>from statsmodels.stats.power import TTestIndPowerpower = TTestIndPower()```</p><p>```python</p><h1>Determine the sample size</h1><p>```</p><p>```python</p><h1><strong>SOLUTION</strong></h1><p>power.solve_power(effect_size=0.17/0.21, alpha=0.05, power=0.8)```</p><pre><code>24.951708908275144</code></pre><p>```python</p><h1>Minimum sample size to start the simulations</h1><p>sample_size = 12null_rejected = 0n_sim = 10000```</p><p>```python</p><h1><strong>SOLUTION</strong></h1><h1>Minimum sample size to start the simulations</h1><p>sample_size = 12null_rejected = 0n_sim = 10000```</p><p>As above, perform the following</p><ul><li>Initialize an empty array for storing results</li><li>initialize a list for storing sample size x power summary</li><li>While current power is less than the target power<ul><li>Generate distributions for control and experimental groups using given statistics (as before)</li><li>Run a t-test and store results</li><li>Calculate current power </li><li>Output current sample size and power calculated for inspection</li><li>Store results: Sample size, power</li><li>increase the sample size by 1 and repeat</li></ul></li></ul><p>```pythonnp.random.seed(10)</p><p>p = (np.empty(n_sim))p.fill(np.nan)</p><p>power_sample = []</p><h1>Keep iterating as shown above until desired power is obtained</h1><p>```</p><p>```python</p><h1><strong>SOLUTION</strong></h1><p>np.random.seed(10)</p><p>p = (np.empty(n_sim))p.fill(np.nan)</p><h1>Keep iterating until desired power is obtained</h1><p>power_sample = []while null_rejected &lt; target:</p><pre><code>data = np.empty([n_sim, sample_size, 2])data.fill(np.nan)# For control group # Here we specify size=[n_sim, sample_size] which creates an array of n_sim number of arrays,# each containing sample_size number of elements. # This is equivalent to manually looping n_sim times like we did above but is much faster.data[:,:,0] = np.random.normal(loc=control_mean, scale=control_sd, size=[n_sim, sample_size])# For experimental groupdata[:,:,1] = np.random.normal(loc=experimental_mean, scale=experimental_sd, size=[n_sim, sample_size])result = stats.ttest_ind(data[:, :, 0],data[:, :, 1],axis=1)p_vals = result[1]# Since you know that all simulations are from a different distribution \\\\# all those that rejected the null-hypothesis are validnull_rejected = np.sum(p_vals &lt; 0.05) / n_simprint(\\'Number of Samples:\\', sample_size,\\', Calculated Power =\\', null_rejected)power_sample.append([sample_size, null_rejected])# increase the number of samples by one for the next iteration of the loopsample_size += 1</code></pre><p>```</p><pre><code>Number of Samples: 12 , Calculated Power = 0.4754Number of Samples: 13 , Calculated Power = 0.5066Number of Samples: 14 , Calculated Power = 0.5423Number of Samples: 15 , Calculated Power = 0.5767Number of Samples: 16 , Calculated Power = 0.6038Number of Samples: 17 , Calculated Power = 0.6297Number of Samples: 18 , Calculated Power = 0.658Number of Samples: 19 , Calculated Power = 0.6783Number of Samples: 20 , Calculated Power = 0.7056Number of Samples: 21 , Calculated Power = 0.7266Number of Samples: 22 , Calculated Power = 0.7481Number of Samples: 23 , Calculated Power = 0.7624Number of Samples: 24 , Calculated Power = 0.7864Number of Samples: 25 , Calculated Power = 0.8031</code></pre><p>You can also plot the calculated power against sample size to visually inspect the effect of increasing sample size. </p><p>```python</p><h1>Plot a sample size X Power line graph</h1><p>```</p><p>```python</p><h1><strong>SOLUTION</strong></h1><h1>Plot a sample size X Power line graph</h1><p>plt.figure(figsize=(10,5))plt.title(\\'Power vs. Sample Size\\')plt.xlabel(\\'Sample Size\\')plt.ylabel(\\'Power\\')</p><p>ans = power_sampledf = pd.DataFrame(ans, index=None)plt.plot(df[0], df[1])</p><p>plt.show()```</p><p><img alt=\"png\" src=\"index_files/index_24_0.png\" /></p><p>This output indicates that in order to get the required power (80%) to detect a difference of 0.17, you would need a considerably higher number of patients. </p><h2>BONUS: Investigating the relationship between Power, Sample Size, and Effect Size</h2><p>You\\'ve seen how to calculate power given alpha, sample size, and effect size. To further investigate this relationship, it is interesting to plot the relationship between power and sample size for various effect sizes. </p><p>To do this, run multiple simulations for varying parameters. Then store the parameters and plot the resulting dataset. Specifically:</p><ol><li>Use a value of $\\\\alpha$ = 0.05 for all of your simulations</li><li>Use the following effect sizes: [0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5]</li><li>Use the sample sizes from 10 to 500</li><li>For each effect size sample size combination, calculate the accompanying power</li><li>Plot a line graph of the power vs sample size relationship. You should have 7 plots; one for each of the effect sizes listed above. All 7 plots can be on the same graph but should be labeled appropriately. Plot the power on the y-axis and sample size on the x-axis.</li></ol><p>```python</p><p>```</p><p>```python</p><h1><strong>SOLUTION</strong></h1><p>def power_curve(min_sample_size = 10, max_sample_size=500, n_sim = 1000, control_mean = 0,                control_sd = 0.21, experimental_mean = 0.17, experimental_sd = 0.21):    p = (np.empty(n_sim))    p.fill(np.nan)</p><pre><code># Keep iterating until desired power is obtainedpower_sample = []for sample_size in range(min_sample_size, max_sample_size, 5):    data = np.empty([n_sim, sample_size, 2])    data.fill(np.nan)    # For control group     data[:,:,0] = np.random.normal(loc=control_mean, scale=control_sd, size=[n_sim, sample_size])    # For experimental group    data[:,:,1] = np.random.normal(loc=experimental_mean, scale=experimental_sd, size=[n_sim, sample_size])    result = stats.ttest_ind(data[:, :, 0],data[:, :, 1],axis=1)    p_vals = result[1]    # Since you know that all simulations are from a different distribution \\\\    # all those that rejected the null-hypothesis are valid    null_rejected = np.sum(p_vals &lt; 0.05) / n_sim    power_sample.append(null_rejected)return power_sample</code></pre><p>cols = {}</p><p>for exp_mean in [0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5]:    col = power_curve(experimental_mean=exp_mean)    cols[exp_mean] = coldf = pd.DataFrame.from_dict(cols)df.index = list(range(10,500,5))df.plot(figsize=(10,10))plt.legend(title=\\'Effect Size\\',loc=(1,0.8))plt.title(\\'Power Curves for Various Sample Sizes and Effect Sizes with Alpha=0.05\\')plt.xlabel(\\'Sample Size\\')plt.ylabel(\\'Power\\');```</p><p><img alt=\"png\" src=\"index_files/index_28_0.png\" /></p><h2>Summary</h2><p>In this lesson, you gained further practice with \"statistical power\" and how it can be used to analyze experimental design. You ran a simulation to determine the sample size that would provide a given value of power (for a given alpha and effect size). Running simulations like this, as well as further investigations regarding required sample sizes for higher power thresholds or smaller effect sizes is critical in designing meaningful experiments where one can be confident in the subsequent conclusions drawn.</p>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIS-Canvas package Completed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import credentials\n",
    "import lesson_content\n",
    "auth = credentials.Credentials('c')\n",
    "remote = False\n",
    "sc=False\n",
    "course_id = 6363\n",
    "headers = {\n",
    "        'Authorization': f'Bearer {auth.API_KEY}'\n",
    "        }\n",
    "\n",
    "if remote:\n",
    "    content = lesson_content.GithubContent(auth.instance, sc, remote_url='')\n",
    "else:\n",
    "    content = lesson_content.LocalContent(auth.instance, sc)\n",
    "\n",
    "if sc:\n",
    "    new_description = f'{content.data_element} {content.header} {content.intro} {content.button}'\n",
    "    \n",
    "else:\n",
    "    new_description = f'{content.data_element} {content.header} {content.html}'\n",
    "\n",
    "    # setting up the payload for delivery\n",
    "\n",
    "payload = {\n",
    "    \"wiki_page[title]\": 'Test',\n",
    "    \"wiki_pages[body]\": new_description\n",
    "    }\n",
    "\n",
    "page_url = f\"{auth.API_PATH}/courses/{course_id}/pages/121212\"\n",
    "\n",
    "put_response = requests.put(page_url, headers=headers, data=payload)\n",
    "print(content.title, 'Completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put_response.json()['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0e42c4d7906c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlesson_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlesson_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_intro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fis-canvas/lesson_content.py\u001b[0m in \u001b[0;36mget_intro\u001b[0;34m(markdown)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_intro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkdown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<h2>.*?</h2>.*?<h2>.*?</h2>.*?</ul.*?>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'</ul>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtarget_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkdown\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'start'"
     ]
    }
   ],
   "source": [
    "import lesson_content\n",
    "lesson_content.get_intro(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'canvas_interface' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-32c4b4c3385d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlesson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanvas_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlesson_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dsc-obtaining-your-data-lab'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'canvas_interface' is not defined"
     ]
    }
   ],
   "source": [
    "lesson = canvas_interface.Assignment(assignments[55])\n",
    "lesson_url = 'dsc-obtaining-your-data-lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch = 'master'\n",
    "url = f'http://raw.githubusercontent.com/learn-co-curriculum/{lesson_url}/{branch}/README.md'\n",
    "resp = requests.get(url)\n",
    "github_content = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<h1>Obtaining Your Data - Lab</h1>\\n<h2>Introduction</h2>\\n<p>In this lab you'll practice your munging and transforming skills in order to load in your data to solve a regression problem.</p>\\n<h2>Objectives</h2>\\n<p>You will be able to:\\n* Perform an ETL process with multiple tables and create a single dataset</p>\\n<h2>Task Description</h2>\\n<p>You just got hired by Lego! Your first project is going to be to develop a pricing algorithm to help set a target price for new lego sets that are released to market. To do this, you're first going to need to start mining the company database in order to collect the information you need to develop a model.</p>\\n<p>Start by investigating the database stored in lego.db and joining the tables into a unified dataset!</p>\\n<blockquote>\\n<p><strong>Hint:</strong> use this SQL query to preview the tables in an unknown database:\\n<code>sql\\nSELECT name FROM sqlite_master\\n            WHERE type='table'\\n            ORDER BY name;</code></p>\\n</blockquote>\\n<p>```python</p>\\n<h1>Your code here</h1>\\n<p>```</p>\\n<h2>Summary</h2>\\n<p>Nice work! You're working more and more independently through the workflow and ensuring data integrity! In this lab, you successfully executed an ETL process to merge different tables!</p>\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5696aaef60fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlesson_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlesson_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_intro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkdown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fis-canvas/lesson_content.py\u001b[0m in \u001b[0;36mget_intro\u001b[0;34m(markdown)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_intro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkdown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<h2>.*?</h2>.*?<h2>.*?</h2>.*?</ul.*?>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'</ul>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    200\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import lesson_content\n",
    "lesson_content.get_intro(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/6gffn8x508j_v8l2wv2zzhlw0000gq/T/tmp9_7sl67g/dsc-analyzing-macbeth-project-pandas-v2-1/.canvas\n",
      "/var/folders/y8/6gffn8x508j_v8l2wv2zzhlw0000gq/T/tmp9_7sl67g \n",
      " ['LICENSE.md', 'dsc-github-actions-files', 'splitter.py', 'README.md', '.gitignore', 'CONTRIBUTING.md', '.github', '.canvas', '.learn', '.git', 'index.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "from tempfile import TemporaryDirectory as tempdir\n",
    "with tempdir() as directory:\n",
    "    path = directory\n",
    "    url = 'git@github.com:learn-co-curriculum/dsc-analyzing-macbeth-project-pandas-v2-1.git'\n",
    "    repo_name = url.split('/')[-1].rstrip('.git')\n",
    "    subprocess.run(['git', 'clone', url],cwd=path)\n",
    "    workingdir = os.path.join(path, repo_name)\n",
    "    lesson_data = yaml.dump({\n",
    "        \"id\": 1234,\n",
    "        \"course_id\": 12345,\n",
    "        \"canvas_url\": 'www.url.com',\n",
    "        \"type\": 'Page', \n",
    "        \"grading_type\": 'curve'})\n",
    "    canvas_file = os.path.join(workingdir, '.canvas')\n",
    "    print(canvas_file)\n",
    "    with open(canvas_file, 'w')as f:\n",
    "        f.write(lesson_data)\n",
    "    contents = (os.listdir(workingdir))\n",
    "    subprocess.run(['cat', '.canvas'], cwd=workingdir)\n",
    "    print(path, '\\n', contents)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dsc-analyzing-macbeth-project-pandas-v2-1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'git@github.com:learn-co-curriculum/dsc-analyzing-macbeth-project-pandas-v2-1.git'\n",
    "repo_name = url.split('/')[-1].rstrip('.git')\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"<div id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-law-of-total-probability\"></div>\n",
    "<header class=\"fis-header\" style=\"visibility: hidden;\"><a class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-law-of-total-probability\" target=\"_blank\" rel=\"noopener\"><img id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\" /></a><a class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-law-of-total-probability/issues/new\" target=\"_blank\" rel=\"noopener\"><img id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\" /></a></header>\n",
    "<h2>Introduction</h2>\n",
    "<p>In this lesson, we'll look at the law of total probability. In probability theory, the law (or formula) of total probability is a fundamental rule relating <strong>marginal probabilities</strong> to conditional probabilities. It expresses the total probability of an outcome that can be realized via several distinct events.</p>\n",
    "<h1>Partitioning and the Law of Total Probability</h1>\n",
    "<h2>Objectives</h2>\n",
    "<p>You will be able to:</p>\n",
    "<ul>\n",
    "    <li>State the law of total probabilities based on a partitioned event space</li>\n",
    "    <li>Explain the concept of event space and partitioning</li>\n",
    "    <li>Describe conditional independence</li>\n",
    "    <li>Perform partitioning based on known and unknown probabilities to solve a problem</li>\n",
    "</ul>\n",
    "<h2>Partitioning a Sample Space</h2>\n",
    "<p>the Law of Total Probability can be used to calculate <img src=\"https://render.githubusercontent.com/render/math?math=P(B)\" /> . The law requires that you have a set of disjoint events <img src=\"https://render.githubusercontent.com/render/math?math=A_i\" /> that collectively \"cover\" the event <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> . Then, instead of calculating <img src=\"https://render.githubusercontent.com/render/math?math=P(B)\" /> directly, you add up the intersection of <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> with each of the events <img src=\"https://render.githubusercontent.com/render/math?math=A_i\" /> . Let's see this graphically below:</p>\n",
    "<p>Let <img src=\"https://render.githubusercontent.com/render/math?math=A_1,%20A_2,%20%5Cdots,%20A_n\" /> partition sample space <img src=\"https://render.githubusercontent.com/render/math?math=S\" /> into disjoint regions that sum up to <img src=\"https://render.githubusercontent.com/render/math?math=S\" /> . In the example, the four regions <img src=\"https://render.githubusercontent.com/render/math?math=A_1,%20A_2,%20A_3\" /> and <img src=\"https://render.githubusercontent.com/render/math?math=A_4\" /> sum up to sample space <img src=\"https://render.githubusercontent.com/render/math?math=S\" /> .</p>\n",
    "<p><img src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-law-of-total-probability/master/images/Image_55_TotProb.png\" width=\"500\" /></p>\n",
    "<p>The probability of a random event <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> (orange area) can be written down as:</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(B)\" /> = <img src=\"https://render.githubusercontent.com/render/math?math=P(B%20%5Ccap%20A1)%20%2b%20P(B%20%5Ccap%20A2)%20%2b%20P(B%20%5Ccap%20A3)%20%2b%20P(B%20%5Ccap%20A4)\" /> = <img src=\"https://render.githubusercontent.com/render/math?math=P(B%20%5Cmid%20A1)P(A1)%20%2b%20P(B%20%5Cmid%20A2)P(A2)%20%2b%20P(B%20%5Cmid%20A3)P(A3)%20%2b%20P(B%20%5Cmid%20A4)P(A4)\" /></p>\n",
    "<p>Here we use the first theorem mentioned in the previous lesson to find the combined probabilities.</p>\n",
    "<h3>Example</h3>\n",
    "<p>Let's use a simple example to clarify the image above! The example is created to match the image.</p>\n",
    "<p>In a certain country, there are four provinces (eg. disjoint regions) <img src=\"https://render.githubusercontent.com/render/math?math=A_1,%20A_2\" /> , <img src=\"https://render.githubusercontent.com/render/math?math=A_3\" /> and <img src=\"https://render.githubusercontent.com/render/math?math=A_4\" /> .</p>\n",
    "<p>You are interested in the total forest area, <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> , in the country.</p>\n",
    "<p>Suppose that you know that the forest area in <img src=\"https://render.githubusercontent.com/render/math?math=A_1\" /> , <img src=\"https://render.githubusercontent.com/render/math?math=A_2\" /> , and <img src=\"https://render.githubusercontent.com/render/math?math=A_3\" /> are 100<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /> , 50<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /> , and 150<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /> , and 0<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /> respectively. What is the total forest area in the country?</p>\n",
    "<p>100<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /> + 50<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /> + 150<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /> + 0<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /> = 300<img src=\"https://render.githubusercontent.com/render/math?math=%5Ctext%7Bkm%7D%5E2\" /></p>\n",
    "<p>We can simply add forest areas in each province to obtain the forest area in the whole country.</p>\n",
    "<p>This is the idea behind the law of total probability, in which the area of forest is replaced by probability of an event <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> . In particular, if you want to find <img src=\"https://render.githubusercontent.com/render/math?math=P(B)\" /> , you can look at a partition of <img src=\"https://render.githubusercontent.com/render/math?math=S\" /> (our sample space composed of <img src=\"https://render.githubusercontent.com/render/math?math=A_1,%5Cldots,%20A_4\" /> ), and add the amount of probability of <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> that falls in each partition.</p>\n",
    "<h3>Two Events</h3>\n",
    "<p>In general, we can say that for any two events <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> and <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> :</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(A)=P(A%20%20%5Ccap%20B)%2bP(A%20%20%5Ccap%20B')\" /></p>\n",
    "<p>and using the definition of conditional probability, <img src=\"https://render.githubusercontent.com/render/math?math=P(A%20%20%5Ccap%20B)=P(A%20%5Cmid%20B)P(B)\" /> , we can write</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(A)=P(A%20%5Cmid%20B)P(B)%2bP(A%20%5Cmid%20B')P(B')\" /></p>\n",
    "<p>The law of total probability is basically a general version of this.</p>\n",
    "<h2>Law of Total Probability</h2>\n",
    "<p>If <img src=\"https://render.githubusercontent.com/render/math?math=B_1\" /> , <img src=\"https://render.githubusercontent.com/render/math?math=B_2\" /> , <img src=\"https://render.githubusercontent.com/render/math?math=B_3\" /> , <img src=\"https://render.githubusercontent.com/render/math?math=%5Cdots\" /> is a partition of the sample space S, then for any event A we have</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(A)=%20%5Csum_i%20P(A%20%20%5Ccap%20B_i)=%20%5Csum_i%20P(A%20%5Cmid%20B_i)P(B_i)\" /></p>\n",
    "<p>Using a Venn diagram, we can pictorially see the idea behind the law of total probability. In the figure below, we have</p>\n",
    "<ul>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=A_1%20=%20A%20%20%5Ccap%20B_1\" /></li>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=A_2%20=%20A%20%20%5Ccap%20B_2\" /></li>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=A_3%20=%20A%20%20%5Ccap%20B_3\" /></li>\n",
    "</ul>\n",
    "<p><img src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-law-of-total-probability/master/images/Image_56_vent.png\" width=\"400\" /></p>\n",
    "<p>As it can be seen from the figure, <img src=\"https://render.githubusercontent.com/render/math?math=A_1\" /> , <img src=\"https://render.githubusercontent.com/render/math?math=A_2\" /> , and <img src=\"https://render.githubusercontent.com/render/math?math=A_3\" /> form a partition of the set A, and thus</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(A)=P(A_1)%2bP(A_2)%2bP(A_3)\" /></p>\n",
    "<p>Here is a typical scenario in which we use the law of total probability. We are interested in finding the probability of an event <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> , but we don't know how to find P(A) directly. Instead, we know the conditional probability of <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> given some events <img src=\"https://render.githubusercontent.com/render/math?math=B_i\" /> , where the <img src=\"https://render.githubusercontent.com/render/math?math=B_i\" /> 's form a partition of the sample space. This way, you can use <img src=\"https://render.githubusercontent.com/render/math?math=P(A)\" /> using the law of total probability</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(A)=%5Csum_i%20P(A%20%5Cmid%20B_i)P(B_i)\" /></p>\n",
    "<h2>More on Partitions</h2>\n",
    "<ul>\n",
    "    <li>The natural numbers <img src=\"https://render.githubusercontent.com/render/math?math=%5Cmathbb%7BN%7D\" /> can be partitioned into even and odd numbers.</li>\n",
    "    <li>The set of animal species in the world can be partitioned into subsets where a subset reflects a continent and each species is positioned in a subset depending on which continent they originated from.</li>\n",
    "</ul>\n",
    "<p>In statistics, choosing the right partitioning is key as bad choices of partitions may results in many sub-problems that are even more difficult to solve.</p>\n",
    "<p><img src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-law-of-total-probability/master/images/Image_57_TotProb_2.png\" width=\"500\" /></p>\n",
    "<p>The probability of <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> can be written as sums of event <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> (note that <img src=\"https://render.githubusercontent.com/render/math?math=B%5Ec\" /> is another way of writing <img src=\"https://render.githubusercontent.com/render/math?math=B'\" />) The total probability rule is:</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(A)%20=%20P(A%20%20%5Ccap%20B)%20%2b%20P(A%20%20%5Ccap%20B%5Ec)\" /></p>\n",
    "<p>An alternate version of the total probability rule (found with the multiplication rule) can be used when the necessary probabilities are known:</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(A)%20=%20P(A%20%5Cmid%20B)%20%20P(B)%20%2b%20P(A%20%5Cmid%20B%5Ec)P(B%5Ec)\" /></p>\n",
    "<p>You need to be careful when dealing with conditional probabilities and conditioning. Let's look at a few examples to see this idea in action.</p>\n",
    "<h3>Example 1</h3>\n",
    "<p>In a certain county in the United States, 60% of registered voters are Republicans, 30% are Democrats and 10% are Independents.</p>\n",
    "<p>When those voters were asked about increasing military spending.</p>\n",
    "<ul>\n",
    "    <li>40% of Republicans opposed it.</li>\n",
    "    <li>65% of the Democrats opposed it.</li>\n",
    "    <li>55% of the Independents opposed it.</li>\n",
    "</ul>\n",
    "<p>What is the probability that a randomly selected voter in this county opposes increased military spending?</p>\n",
    "<p>You know that:</p>\n",
    "<ul>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=%5COmega\" /> = {registered voters in the county}</li>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=R\" /> = {registered republicans}, <img src=\"https://render.githubusercontent.com/render/math?math=P(R)\" /> = 0.6</li>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=D\" /> = {registered democrats}, <img src=\"https://render.githubusercontent.com/render/math?math=P(D)\" /> = 0.3</li>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=I\" /> = {registered independents}, <img src=\"https://render.githubusercontent.com/render/math?math=P(I)\" /> = 0.1</li>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=B\" /> = {registered voters opposing increased military spending}</li>\n",
    "</ul>\n",
    "<p>You also know that:</p>\n",
    "<ul>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=P(B%20%5Cmid%20R)%20=%200.4\" /></li>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=P(B%20%5Cmid%20D)%20=%200.65\" /></li>\n",
    "    <li><img src=\"https://render.githubusercontent.com/render/math?math=P(B%20%5Cmid%20I)%20=%200.55\" /></li>\n",
    "</ul>\n",
    "<p>By the total probability theorem:</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=Pr(B)%20=%20Pr(B%20%5Cmid%20R)%20Pr(R)%20%2b%20Pr(B%20%5Cmid%20D)%20Pr(D)%20%2b%20Pr(B%20%5Cmid%20I)%20Pr(I)\" /> <img src=\"https://render.githubusercontent.com/render/math?math==%20(0.4%20*%200.6)%20%2b%20(0.65%20*%200.3)%20%2b%20(0.55%20*%200.1)%20=%200.49\" /></p>\n",
    "<h3>Example 2</h3>\n",
    "<p>Let's consider a 2-card hand drawn from a standard playing deck. What is the probability of drawing 2 aces, given that we know one of the cards is an ace?</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(%5Ctext%7Bboth%20are%20aces%20%7C%20one%20is%20ace%7D)%20=%20%5Cdfrac%7BP(%5Ctext%7Bboth%20are%20aces%7D)%7D%7BP(%5Ctext%7Bone%20is%20ace%7D)%7D%20=%20%5Cdfrac%7BP(%5Ctext%7Bboth%20are%20aces%7D)%7D%7B1%20-%20P(%5Ctext%7Bneither%20is%20ace%7D)%7D%20=%5Cdfrac%7B%5Cbinom%7B4%7D%7B2%7D/%5Cbinom%7B52%7D%7B2%7D%7D%7B1%20-%20%5Cbinom%7B48%7D%7B2%7D/%5Cbinom%7B52%7D%7B2%7D%7D=%5Cdfrac%7B1%7D%7B33%7D\" /></p>\n",
    "<p>But now think about this: What is the probability of drawing 2 aces, knowing that one of the cards <strong>is the ace of spades</strong>?</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(%5Ctext%7Bboth%20are%20aces%20%7C%20ace%20of%20spades%7D)%20=%20P(%5Ctext%7Bother%20card%20is%20also%20an%20ace%7D)%20=%20%5Cdfrac%7B3%7D%7B51%7D=%20%5Cdfrac%7B1%7D%7B17%7D\" /></p>\n",
    "<p><em>Notice how the fact that we know we have the ace of spades nearly doubles the probability of having 2 aces</em></p>\n",
    "<h3>Example 3</h3>\n",
    "<p>Suppose there is a test for a disease, and this test is said to be \"95% accurate\". The disease in question afflicts 1% of the population. Now say that there is a patient who tests positive for this disease under this test.</p>\n",
    "<p>First, we define the events in question:</p>\n",
    "<p>Let <img src=\"https://render.githubusercontent.com/render/math?math=D\" /> be the event that the patient actually has the disease.</p>\n",
    "<p>Let <img src=\"https://render.githubusercontent.com/render/math?math=T\" /> be the event that the patient tests positive.</p>\n",
    "<p>Since that phrase \"95% accurate\" is ambiguous, we need to clarify that.</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(T%7CD)%20=%20P(T%5Ec%7CD%5Ec)%20=%200.95\" /></p>\n",
    "<p>In other words, <strong>conditioning on whether or not the patient has the disease</strong>, we will assume that the test is 95% accurate.</p>\n",
    "<p><em>What exactly are we trying to find?</em></p>\n",
    "<p>What the patient really wants to know is not <img src=\"https://render.githubusercontent.com/render/math?math=P(T%7CD)\" /> , which is the accuracy of the test; but rather <img src=\"https://render.githubusercontent.com/render/math?math=P(D%7CT)\" /> , or the probability she has the disease given that the test returns positive. Fortunately, we know how <img src=\"https://render.githubusercontent.com/render/math?math=P(T%7CD)\" /> relates to <img src=\"https://render.githubusercontent.com/render/math?math=P(D%7CT)\" /> .</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(D%7CT)\" /> = <img src=\"https://render.githubusercontent.com/render/math?math=%5Cfrac%7BP(T%7CD)P(D)%7D%7BP(T)%7D\" /> (Bayes Rule)</p>\n",
    "<p>= <img src=\"https://render.githubusercontent.com/render/math?math=%5Cfrac%7BP(T%7CD)P(D)%7D%7BP(T%7CD)P(D)%20%2b%20P(T%7CD%5Ec)P(D%5Ec)%7D\" /> (by the Law of Total Probability)</p>\n",
    "<p>= <img src=\"https://render.githubusercontent.com/render/math?math=%5Cfrac%7B(0.95)(0.01)%7D%7B(0.95)(0.01)%20%2b%20(0.05)(0.99)%7D\" /> (the rarity of the disease competes with the rarity of true negatives)</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=%5Capprox%200.16\" /></p>\n",
    "<h2>Common Pitfalls</h2>\n",
    "<ul>\n",
    "    <li>\n",
    "        <p>Mistaking <img src=\"https://render.githubusercontent.com/render/math?math=P(A%7CB)\" /> for <img src=\"https://render.githubusercontent.com/render/math?math=P(B%7CA)\" /></p>\n",
    "        <p>This is also known as the <a href=\"https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy\">Prosecutor's Fallacy</a>, where instead of asking about the <em>probability of guilt (or innocence) given all the evidence</em>, we make the mistake of concerning ourselves with the <em>probability of the evidence given guilt</em>.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <p>Confusing <em>prior</em> <img src=\"https://render.githubusercontent.com/render/math?math=P(A)\" /> with <em>posterior</em> <img src=\"https://render.githubusercontent.com/render/math?math=P(A%20%5Cmid%20B)\" /></p>\n",
    "        <p>Observing that event <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> occurred does <strong>not</strong> mean that <img src=\"https://render.githubusercontent.com/render/math?math=P(A)%20=%201\" /> . But <img src=\"https://render.githubusercontent.com/render/math?math=P(A%20%5Cmid%20A)%20=%201\" /> and <img src=\"https://render.githubusercontent.com/render/math?math=P(A)%20%5Cneq%201\" /> .</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <p>Confusing <em>independence</em> with <strong>conditional independence</strong></p>\n",
    "        <p>This is more subtle than the other two. Let's look at this in a bit more detail</p>\n",
    "    </li>\n",
    "</ul>\n",
    "<h2>Conditional Independence</h2>\n",
    "<p>Events <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> and <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> are <strong>conditionally independent</strong> given event <img src=\"https://render.githubusercontent.com/render/math?math=C\" /> , if:</p>\n",
    "<p><img src=\"https://render.githubusercontent.com/render/math?math=P(A%20%20%5Ccap%20B%20%5Cmid%20C)%20=%20P(A%20%5Cmid%20C)P(B%20%5Cmid%20C)\" /></p>\n",
    "<p>i.e. conditioning on event <img src=\"https://render.githubusercontent.com/render/math?math=C\" /> does not give us any additional information on <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> or <img src=\"https://render.githubusercontent.com/render/math?math=B\" /> .</p>\n",
    "<h3>Conditional independence given <img src=\"https://render.githubusercontent.com/render/math?math=C\" /> DOES NOT imply unconditional independence</h3>\n",
    "<p>Consider playing a series of 5 games against a chess opponent of unknown strength. Winning all five games would give you a good idea that you are a better player. So winning each successive game is actually providing us with information about the strength of our opponent. If you have prior knowledge about the strength of your opponent, you condition on the strength of our opponent i.e. winning one game would not provide us with any additional information on the probability of winning the next. Having no prior knowledge of your opponent and winning a string a games will give you information about the probability of winning the next game.</p>\n",
    "<p>The games are conditionally independent given the strength of our opponent, but <strong>not</strong> independent unconditionally.</p>\n",
    "<h3>Unconditional independence DOES NOT imply conditional independence given <img src=\"https://render.githubusercontent.com/render/math?math=C\" /></h3>\n",
    "<p>For example, let <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> be the event of the fire alarm going off, <img src=\"https://render.githubusercontent.com/render/math?math=F\" /> be the event of a fire, and <img src=\"https://render.githubusercontent.com/render/math?math=C\" /> be the event of someone making popcorn. Suppose that either <img src=\"https://render.githubusercontent.com/render/math?math=F\" /> or <img src=\"https://render.githubusercontent.com/render/math?math=C\" /> will result in <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> and the fire alarm going off. Now if <img src=\"https://render.githubusercontent.com/render/math?math=F\" /> and <img src=\"https://render.githubusercontent.com/render/math?math=C\" /> are independent: knowing that there's a fire <img src=\"https://render.githubusercontent.com/render/math?math=F\" /> doesn't tell you anything about anyone making popcorn <img src=\"https://render.githubusercontent.com/render/math?math=C\" /> , and vice versa. But the probability of a fire given that the alarm goes off <strong>and</strong> no one is making any popcorn is given by <img src=\"https://render.githubusercontent.com/render/math?math=P(F%20%5Cmid%20A,C%5Ec)%20=%201\" /> . After all, if the fire alarm goes off and no one is making popcorn, there can only be one explanation: <em>there must be a fire</em>.</p>\n",
    "<p>So <img src=\"https://render.githubusercontent.com/render/math?math=F\" /> and <img src=\"https://render.githubusercontent.com/render/math?math=C\" /> may be independent, but they are not <em>conditionally independent</em> when we condition on event <img src=\"https://render.githubusercontent.com/render/math?math=A\" /> . Knowing that nobody is making any popcorn when the alarm goes off can only mean that there is a fire.</p>\n",
    "<h2>Additional Resources</h2>\n",
    "<p>You are strongly advised to visit following links to get an indepth understanding with examples and proofs for formulas highlighted in this lesson.</p>\n",
    "<p><a class=\"\" href=\"https://www.youtube.com/watch?v=J7Evcn4lfhc\">The law of total probability - concept and proof</a> - Excellent YouTube video by Phil Chan.</p>\n",
    "<p><a href=\"https://jeremykun.com/2013/03/28/conditional-partitioned-probability-a-primer/\">Conditional (Partitioned) Probability &mdash; A Primer</a> - Deep dive into partitions (A Must Read)</p>\n",
    "<p><a href=\"https://www.sangakoo.com/en/unit/law-of-total-probability\">Law of Total Probability</a> - More examples for a deeper understanding around partitioning</p>\n",
    "<h2>Summary</h2>\n",
    "<p>In this lesson, you further learned about the ideas of conditional probability covered in the previous lessons to explain the law of total probability using partitioning of the sample space. You learned how you can partition probabilities with respect to some other event, when the direct probabilities are not known. Let's move on to some practice!</p>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning and the Law of Total Probability\n"
     ]
    }
   ],
   "source": [
    "from lesson_content import make_title\n",
    "title = make_title(html)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
